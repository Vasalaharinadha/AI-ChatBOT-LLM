{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2519d844",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff17f108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      " Hii, How are you?\"\n",
      "\n",
      "\"I'm fine. I'm just a little bit tired.\"\n",
      ".\n",
      ",\n",
      "-\n",
      "The next day, the next morning, and the day after, I woke up. It was a very cold day. The sun was still shining, but it was getting colder. My body was cold. And I was feeling very tired. So I went to the doctor. He said, \"I don't know if you're feeling tired or not\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"  # Small version of GPT-2\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Make sure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to generate text based on a prompt\n",
    "def generate_text(prompt, max_length=100):\n",
    "    # Encode the input prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate output text\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2, top_p=0.95, temperature=1.5)\n",
    "\n",
    "    # Decode the generated output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"Hii, How are you \"\n",
    "generated_text = generate_text(prompt, max_length=100)\n",
    "\n",
    "print(\"Generated Text:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce4e23",
   "metadata": {},
   "source": [
    "# AI Chatbot  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d05d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hey, I am a historical agent AI, You can ask anything around it.\n",
      "User: Hey, I am travelling to Noida next month for official work can you suggest me something be visit.\n",
      "Bot: Hey, have you visited Taj Mahal in Agra before?\n",
      "User: No, this is my first visit to India.\n",
      "Bot: Great, I think you must visit Taj Mahal in Agra, Agra is around 200Km from Noida and one can easily take a cab from Noida to Agra.\n",
      "Bot: If you can share your email, I can send few details related to Taj Mahal.\n",
      "User: No Thanks, I am in a hurry. later.\n",
      "Bot: Thanks, I have sent a 6-digit code to your email No Thanks, I am in a hurry. later., can you please confirm with the code.\n",
      "Error sending email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\\n5.7.8  https://support.google.com/mail/?p=BadCredentials d9443c01a7336-223501d329dsm110112825ad.27 - gsmtp')\n",
      "User: 2452\n",
      "Bot: Sorry, that's incorrect. Can you please check again?\n",
      "User: okay thanks\n",
      "Bot: Sorry, that's incorrect. Can you please check again?\n",
      "User: okay\n",
      "Bot: Sorry, that's incorrect. Can you please check again?\n",
      "User: \n",
      "Bot: Sorry, that's incorrect. Can you please check again?\n",
      "User: \n",
      "Bot: Sorry, that's incorrect. Can you please check again?\n",
      "User: no\n",
      "Bot: Sorry, that's incorrect. Can you please check again?\n",
      "User: No\n",
      "Bot: Sorry, that's incorrect. Can you please check again?\n",
      "User: no thanks\n",
      "Bot: Sorry, that's incorrect. Can you please check again?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import smtplib\n",
    "\n",
    "# Database for historical monuments\n",
    "database = {\n",
    "    \"Taj Mahal\": \"Located in Agra, India, the Taj Mahal is a symbol of love built by Mughal Emperor Shah Jahan.\",\n",
    "    \"Great Wall of China\": \"The Great Wall of China is a series of fortifications built to protect China from invasions.\",\n",
    "    \"Pyramids of Giza\": \"The Pyramids of Giza are ancient pyramids located in Egypt, built as tombs for pharaohs.\"\n",
    "}\n",
    "\n",
    "# Email credentials (for testing only, do not use in production)\n",
    "EMAIL_USER = \"vasalaharinadha@gmail.com\"\n",
    "EMAIL_PASS = \"don632568896118\"\n",
    "\n",
    "def start_conversation():\n",
    "    print(\"Bot: Hey, I am a historical agent AI, You can ask anything around it.\")\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    if \"Noida\" in user_input:\n",
    "        print(\"Bot: Hey, have you visited Taj Mahal in Agra before?\")\n",
    "        user_input = input(\"User: \")\n",
    "\n",
    "        if \"No\" in user_input:\n",
    "            print(\"Bot: Great, I think you must visit Taj Mahal in Agra, Agra is around 200Km from Noida and one can easily take a cab from Noida to Agra.\")\n",
    "            print(\"Bot: If you can share your email, I can send few details related to Taj Mahal.\")\n",
    "            user_input = input(\"User: \")\n",
    "\n",
    "            if user_input.lower() != \"no thanks\":\n",
    "                email = user_input\n",
    "                send_otp(email)\n",
    "        else:\n",
    "            print(\"Bot: That's great, I am sure you'll enjoy your trip.\")\n",
    "\n",
    "def send_otp(email):\n",
    "    otp = random.randint(100000, 999999)\n",
    "    print(f\"Bot: Thanks, I have sent a 6-digit code to your email {email}, can you please confirm with the code.\")\n",
    "    send_email_otp(email, otp)\n",
    "    \n",
    "    user_otp = input(\"User: \")\n",
    "    verify_otp(user_otp, otp)\n",
    "\n",
    "def send_email_otp(email, otp):\n",
    "    try:\n",
    "        # Set up the SMTP server\n",
    "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        server.starttls()\n",
    "        server.login(EMAIL_USER, EMAIL_PASS)  # Using given email and password\n",
    "        \n",
    "        # Send the email with the OTP\n",
    "        subject = \"Your OTP Code\"\n",
    "        body = f\"Your OTP code for email verification is {otp}.\"\n",
    "        message = f\"Subject: {subject}\\n\\n{body}\"\n",
    "        \n",
    "        server.sendmail(EMAIL_USER, email, message)\n",
    "        server.quit()\n",
    "        print(\"Bot: OTP has been sent successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending email: {e}\")\n",
    "\n",
    "def verify_otp(user_otp, correct_otp):\n",
    "    while user_otp != str(correct_otp):\n",
    "        print(\"Bot: Sorry, that's incorrect. Can you please check again?\")\n",
    "        user_otp = input(\"User: \")\n",
    "    \n",
    "    print(\"Bot: Great! OTP verified successfully. I’ll shoot you an email soon. Take care.\")\n",
    "\n",
    "# Start the conversation\n",
    "start_conversation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fbe690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa076b03",
   "metadata": {},
   "source": [
    "# Finn Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import smtplib\n",
    "import psycopg2\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.graph import END\n",
    "\n",
    "# Set up PostgreSQL connection with example credentials\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"historical_db\",\n",
    "    user=\"admin\",\n",
    "    password=\"password123\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Function to fetch historical monument details\n",
    "def get_monument_info(name):\n",
    "    cursor.execute(\"SELECT description FROM monuments WHERE name = %s\", (name,))\n",
    "    result = cursor.fetchone()\n",
    "    return result[0] if result else \"Sorry, I don't have information on that monument.\"\n",
    "\n",
    "# Function to send OTP\n",
    "def send_email_otp(email, otp):\n",
    "    try:\n",
    "        EMAIL_USER = os.getenv(\"EMAIL_USER\") or \"testemail@gmail.com\"\n",
    "        EMAIL_PASS = os.getenv(\"EMAIL_PASS\") or \"securepass123\"\n",
    "        \n",
    "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        server.starttls()\n",
    "        server.login(EMAIL_USER, EMAIL_PASS)\n",
    "        \n",
    "        subject = \"Your OTP Code\"\n",
    "        body = f\"Your OTP code is {otp}.\"\n",
    "        message = f\"Subject: {subject}\\n\\n{body}\"\n",
    "        \n",
    "        server.sendmail(EMAIL_USER, email, message)\n",
    "        server.quit()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending email: {e}\")\n",
    "        return False\n",
    "\n",
    "# Define the LangGraph conversation state\n",
    "class ConversationState:\n",
    "    messages: list\n",
    "    otp: int = None\n",
    "    email: str = None\n",
    "\n",
    "# Define the LangGraph workflow\n",
    "def start_conversation(state: ConversationState):\n",
    "    return {\"messages\": [SystemMessage(content=\"Hey, I am a historical agent AI. You can ask anything about historical monuments.\")]}  \n",
    "\n",
    "def process_user_input(state: ConversationState, user_input: str):\n",
    "    response = get_monument_info(user_input)  \n",
    "    state.messages.append(AIMessage(content=response))\n",
    "    return {\"messages\": state.messages}\n",
    "\n",
    "def ask_email(state: ConversationState):\n",
    "    state.messages.append(AIMessage(content=\"Would you like me to send more details via email?\"))\n",
    "    return {\"messages\": state.messages}\n",
    "\n",
    "def send_otp_email(state: ConversationState, email: str):\n",
    "    otp = random.randint(100000, 999999)\n",
    "    state.otp = otp\n",
    "    state.email = email\n",
    "    \n",
    "    if send_email_otp(email, otp):\n",
    "        state.messages.append(AIMessage(content=f\"OTP has been sent to {email}. Please enter the OTP to verify.\"))\n",
    "    else:\n",
    "        state.messages.append(AIMessage(content=\"Failed to send OTP. Please try again later.\"))\n",
    "    return {\"messages\": state.messages}\n",
    "\n",
    "def verify_otp(state: ConversationState, user_otp: str):\n",
    "    if str(state.otp) == user_otp:\n",
    "        state.messages.append(AIMessage(content=\"OTP verified successfully! I’ll send you more details soon.\"))\n",
    "    else:\n",
    "        state.messages.append(AIMessage(content=\"Incorrect OTP. Please try again.\"))\n",
    "    return {\"messages\": state.messages}\n",
    "\n",
    "# Build the LangGraph workflow\n",
    "graph = StateGraph(ConversationState)\n",
    "graph.add_node(\"start\", start_conversation)\n",
    "graph.add_node(\"user_input\", process_user_input)\n",
    "graph.add_node(\"ask_email\", ask_email)\n",
    "graph.add_node(\"send_otp\", send_otp_email)\n",
    "graph.add_node(\"verify_otp\", verify_otp)\n",
    "\n",
    "graph.set_entry_point(\"start\")\n",
    "graph.add_edge(\"user_input\", \"ask_email\")\n",
    "graph.add_edge(\"ask_email\", \"send_otp\")\n",
    "graph.add_edge(\"send_otp\", \"verify_otp\")\n",
    "graph.add_edge(\"verify_otp\", END)\n",
    "\n",
    "graph.compile()\n",
    "\n",
    "def run_chat():\n",
    "    state = ConversationState(messages=[])\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "        result = graph.invoke(\"user_input\", state, user_input=user_input)\n",
    "        for message in result[\"messages\"]:\n",
    "            print(f\"Bot: {message.content}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ef89b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
